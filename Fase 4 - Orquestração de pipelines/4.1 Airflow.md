# Fase 4 - Orquestração de pipelines

## Airflow como ferramenta de orquestração

O Apache Airflow é uma plataforma de código aberto amplamente utilizada para orquestrar pipelines de dados. Ele permite criar fluxos de trabalho programáveis e monitorá-los em tempo real, simplificando a automação de processos complexos.

Nesta etapa, você será introduzido(a) aos conceitos fundamentais do Airflow e aprenderá como utilizá-lo na prática para orquestrar pipelines de dados. O objetivo é que você entenda como criar, gerenciar e monitorar processos utilizando essa poderosa ferramenta.

Como a Cognitivo utiliza o Airflow como plataforma padrão de orquestração, o conhecimento aprofundado dos conceitos da ferramenta é essencial. Abaixo você vai encontrar alguns materiais que devem ser consumidos com atenção sobre a ferramenta:

- [Executando o Airflow no Docker](https://airflow.apache.org/docs/apache-airflow/2.1.1/start/docker.html)
- [Introdução ao Apache Airflow - Um guia básico](https://myeasybi.com/2024/04/12/introducao-ao-airflow-guia-basico/)
- [Video: como utilizar o Apache Airflow na prática](https://www.youtube.com/watch?v=cET2DwVhnc4)
- [Video: data pipelines inteligentes com Apache Airflow](https://www.youtube.com/watch?v=0vgL_aC6ecQ&list=PLjwVjYMyoFoHhMuZU656MbqdN5QbTiOcY)

É possível também realizar o Learning Path do Astronomer (startup que foca em acelerar o Airflow), auxiliando na fixação de certos conceitos e particularidades da ferramenta:

- [Astronomer: Airflow 101 Learning Path](https://academy.astronomer.io/path/airflow-101)

Abaixo você também vai encontrar uma compilação dos estudos de um dos integrantes da equipe, demonstrando o código e prints de algumas dags, desde mais simples, até com maiores complexidades e funcionalidades:

- [Compilação de estudos do Airflow - Gabriel Bello](https://docs.google.com/document/d/1onC6CYI-Yc6SZ0AzIc0_ysAvOWJykfUkMoeJJzJnxUs/edit?usp=sharing)