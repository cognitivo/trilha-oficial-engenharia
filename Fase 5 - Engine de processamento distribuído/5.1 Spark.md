# Fase 5 - Engine de processamento distribuído

## Spark como ferramenta pra processamento de grandes conjuntos de dados

O Apache Spark é uma das ferramentas mais populares e poderosas para processamento distribuído de dados em larga escala. Ele é amplamente utilizado em cenários que exigem alta performance, em ambientes de processamento em batch ou streaming.

Nesta etapa, você será introduzido(a) aos conceitos fundamentais do Spark, entendendo sua arquitetura, componentes e principais vantagens para o processamento de dados distribuídos.

[Introdução ao Apache Spark: conhecendo seus componentes, arquitetura e vantagens](https://medium.com/@habbema/vamos-brincar-com-o-spark-eb3e7b7887a9#:~:text=O%20Spark%20%C3%A9%20uma%20solu%C3%A7%C3%A3o,streaming%20e%20aprendizado%20de%20m%C3%A1quina.)

[Apache Spark: o que é? Por que precisamos dele?](https://medium.com/@ingoreichertjr/apache-spark-o-que-%C3%A9-por-que-precisamos-dele-b4c069f9bd67)

[Spark 101: introdução ao framework de processamento distribupido](https://medium.com/gabriel-luz/spark-101-introdu%C3%A7%C3%A3o-ao-framework-de-processamento-de-dados-distribu%C3%ADdos-1f959e596024)

