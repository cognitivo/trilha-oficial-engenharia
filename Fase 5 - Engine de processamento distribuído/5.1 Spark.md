# Fase 5 - Engine de processamento distribuído

## Spark como ferramenta pra processamento de grandes conjuntos de dados

O Apache Spark é uma das ferramentas mais poderosas e populares para o processamento distribuído de dados em larga escala. Ele é amplamente utilizado em cenários que exigem alta performance, como processamento em batch ou streaming, além de ser uma solução essencial para trabalhos que envolvem grandes volumes de dados e necessidade de escalabilidade.

Nesta etapa, você será introduzido(a) aos conceitos fundamentais do Spark, com foco em compreender sua arquitetura distribuída, explorar seus principais componentes e entender as vantagens dessa engine em comparação com outras ferramentas de processamento.

Para desenvolver uma base sólida, explore com atenção os materiais indicados abaixo:

- [Introdução ao Apache Spark: conhecendo seus componentes, arquitetura e vantagens](https://medium.com/@habbema/vamos-brincar-com-o-spark-eb3e7b7887a9#:~:text=O%20Spark%20%C3%A9%20uma%20solu%C3%A7%C3%A3o,streaming%20e%20aprendizado%20de%20m%C3%A1quina.)

- [Apache Spark: o que é? Por que precisamos dele?](https://medium.com/@ingoreichertjr/apache-spark-o-que-%C3%A9-por-que-precisamos-dele-b4c069f9bd67)

- [Spark 101: introdução ao framework de processamento distribupido](https://medium.com/gabriel-luz/spark-101-introdu%C3%A7%C3%A3o-ao-framework-de-processamento-de-dados-distribu%C3%ADdos-1f959e596024)

