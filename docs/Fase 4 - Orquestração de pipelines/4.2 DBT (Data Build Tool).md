# Fase 4 - TransformaÃ§Ã£o e OrquestraÃ§Ã£o de Pipelines ğŸ¬

## DBT (Data Build Tool) - TransformaÃ§Ã£o de Dados ğŸ”„

O **DBT (Data Build Tool)** Ã© uma ferramenta que permite que analistas e engenheiros de dados transformem dados em seus data warehouses usando apenas SQL. DBT nÃ£o extrai ou carrega dados; ele foca exclusivamente na transformaÃ§Ã£o, seguindo o paradigma **ELT (Extract, Load, Transform)**.

Com o conhecimento de **SQL** que vocÃª adquiriu anteriormente, agora vocÃª aprenderÃ¡ como o DBT organiza e gerencia transformaÃ§Ãµes SQL de forma profissional, tornando-as modular, testÃ¡vel, documentada e versionÃ¡vel. ğŸ› ï¸

### Por que DBT? ğŸ¯

#### 1. TransformaÃ§Ã£o Baseada em SQL
DBT utiliza SQL puro, permitindo que vocÃª aproveite todo seu conhecimento de SQL para transformar dados sem precisar aprender uma nova linguagem.

#### 2. Modularidade e ReutilizaÃ§Ã£o
DBT permite criar **models** (modelos) reutilizÃ¡veis, onde cada model Ã© um arquivo SQL que pode referenciar outros models, criando uma hierarquia clara de transformaÃ§Ãµes.

#### 3. Versionamento e Controle
Todo cÃ³digo DBT Ã© versionado com Git, permitindo colaboraÃ§Ã£o, revisÃ£o de cÃ³digo e controle de mudanÃ§as.

#### 4. Testes de Dados
DBT oferece um framework de testes que permite validar a qualidade dos dados automaticamente (testes de unicidade, nÃ£o-nulos, relacionamentos, etc.).

#### 5. DocumentaÃ§Ã£o AutomÃ¡tica
DBT gera documentaÃ§Ã£o automÃ¡tica baseada em comentÃ¡rios e metadados, criando um catÃ¡logo de dados self-service.


### Conceitos Fundamentais do DBT ğŸ“š

#### 1. Models (Modelos)
Um **model** Ã© um arquivo `.sql` que contÃ©m uma query SELECT. Cada model se torna uma tabela ou view no data warehouse.

**Exemplo** (`models/staging/stg_orders.sql`):
```sql
SELECT 
    order_id,
    customer_id,
    order_date,
    total_amount,
    status
FROM {{ source('raw_data', 'orders') }}
WHERE order_date >= '2026-01-01'
```

#### 2. Sources (Fontes)
**Sources** sÃ£o referÃªncias a tabelas externas (raw data) que nÃ£o sÃ£o gerenciadas pelo DBT. Eles permitem documentar e testar dados de origem.

**Exemplo** (`models/sources.yml`):
```yaml
sources:
  - name: raw_data
    description: "Dados brutos do sistema de vendas"
    tables:
      - name: orders
        description: "Tabela de pedidos"
```

#### 3. Tests (Testes)
**Tests** validam a qualidade dos dados. Podem ser testes genÃ©ricos (built-in) ou testes customizados.

**Exemplo** (`models/schema.yml`):
```yaml
models:
  - name: stg_orders
    columns:
      - name: order_id
        tests:
          - unique
          - not_null
      - name: customer_id
        tests:
          - relationships:
              to: source('raw_data', 'customers')
              field: customer_id
```

#### 4. Snapshots
**Snapshots** capturam mudanÃ§as em dados lentamente mutÃ¡veis, permitindo histÃ³rico e anÃ¡lise temporal.

### Estrutura de um Projeto DBT ğŸ“

```
my_dbt_project/
â”œâ”€â”€ dbt_project.yml          # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ profiles.yml             # Credenciais de conexÃ£o
â”œâ”€â”€ models/                  # Models SQL
â”‚   â”œâ”€â”€ staging/            # Camada de staging (limpeza inicial)
â”‚   â”œâ”€â”€ intermediate/       # TransformaÃ§Ãµes intermediÃ¡rias
â”‚   â””â”€â”€ marts/              # Camada final (analytics-ready)
â”œâ”€â”€ macros/                  # Macros reutilizÃ¡veis
â”œâ”€â”€ tests/                   # Testes customizados
â”œâ”€â”€ snapshots/               # Snapshots
â”œâ”€â”€ seeds/                   # Dados de referÃªncia (CSV)
â””â”€â”€ analysis/                # AnÃ¡lises ad-hoc
```

### Camadas de TransformaÃ§Ã£o (Data Modeling Layers) ğŸ—ï¸

#### 1. Staging (Stg)
**Objetivo**: Limpeza inicial e padronizaÃ§Ã£o dos dados brutos.

**CaracterÃ­sticas**:
- Uma tabela staging para cada tabela source
- Nomes padronizados (snake_case)
- Tipos de dados corretos
- Filtros bÃ¡sicos

#### 2. Intermediate (Int)
**Objetivo**: TransformaÃ§Ãµes intermediÃ¡rias e lÃ³gica de negÃ³cio complexa.

**CaracterÃ­sticas**:
- Combina mÃºltiplas tabelas staging
- CÃ¡lculos e agregaÃ§Ãµes intermediÃ¡rios
- Prepara dados para a camada final

#### 3. Marts
**Objetivo**: Tabelas prontas para consumo por usuÃ¡rios finais (BI, Analytics).

**CaracterÃ­sticas**:
- Modelos de negÃ³cio especÃ­ficos
- Dados agregados e resumidos
- Alta performance para queries

### Arquitetura MedalhÃ£o (Medallion Architecture) ğŸ…

A **Arquitetura MedalhÃ£o** Ã© um padrÃ£o de organizaÃ§Ã£o de dados em camadas que o DBT suporta muito bem:

#### Bronze Layer (Dados Brutos)
- Dados ingeridos diretamente das fontes (sources)
- Sem transformaÃ§Ãµes, dados como vieram
- Objetivo: Preservar dados originais

#### Silver Layer (Dados Limpos)
- Dados limpos e validados
- PadronizaÃ§Ã£o de formatos e tipos
- RemoÃ§Ã£o de duplicatas e tratamento de nulos
- Objetivo: Dados confiÃ¡veis e normalizados

#### Gold Layer (Dados para Analytics)
- AgregaÃ§Ãµes e resumos
- Modelos de negÃ³cio especÃ­ficos
- Prontos para consumo por BI e analytics
- Objetivo: Dados prontos para decisÃµes

**Exemplo de estrutura DBT com MedalhÃ£o:**
```
models/
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ bronze_raw_data.sql
â”œâ”€â”€ silver/
â”‚   â””â”€â”€ silver_cleaned_data.sql
â””â”€â”€ gold/
    â””â”€â”€ gold_analytics.sql
```

### Comandos DBT Essenciais ğŸ”§

```bash
# Instalar DBT
pip install dbt-core dbt-athena-community  # ou dbt-snowflake, dbt-bigquery, etc.

# Inicializar projeto
dbt init my_project

# Executar models
dbt run

# Executar apenas models especÃ­ficos
dbt run --select staging
dbt run --select +orders  # + inclui dependÃªncias

# Executar testes
dbt test

# Gerar documentaÃ§Ã£o
dbt docs generate
dbt docs serve

# Executar tudo (run + test)
dbt build

# Compilar SQL (sem executar)
dbt compile

# Executar snapshots
dbt snapshot
```

### Materiais de Aprendizado ğŸ“–

Abaixo, vocÃª encontra materiais essenciais sobre DBT:

#### DocumentaÃ§Ã£o Oficial:
- [ğŸ“š DocumentaÃ§Ã£o Oficial do DBT](https://docs.getdbt.com/docs/introduction) - Guia completo e referÃªncia oficial

#### Artigos e Tutoriais:
- [ğŸ“ DBT - Data Build Tool: Guia Completo](https://bixtecnologia.com.br/dbt-data-build-tool/) - Artigo em portuguÃªs sobre DBT
- [ğŸ“‹ DBT Cheat Sheet](https://www.decube.io/post/dbt-cheat-sheet) - ReferÃªncia rÃ¡pida de comandos e conceitos

### Boas PrÃ¡ticas com DBT âœ¨

1. **Organize em Camadas**: Bronze â†’ Silver â†’ Gold (Arquitetura MedalhÃ£o) ou Staging â†’ Intermediate â†’ Marts
2. **Nomeie de Forma Descritiva**: Use prefixos (bronze_, silver_, gold_, stg_, int_, dim_, fct_) para indicar camada e propÃ³sito
3. **Documente Tudo**: Use `schema.yml` para documentar models, colunas e relacionamentos
4. **Teste Regularmente**: Adicione testes para garantir qualidade dos dados
5. **Use Macros**: Crie macros para lÃ³gicas repetidas e aproveite pacotes como `dbt_utils`
6. **Versionamento**: Sempre trabalhe com Git, commite mudanÃ§as incrementais
7. **IdempotÃªncia**: Models devem poder ser executados mÃºltiplas vezes sem causar duplicaÃ§Ã£o

### DBT e Airflow ğŸ”„

Em projetos reais, o **Airflow** frequentemente orquestra pipelines DBT, executando comandos DBT como tarefas dentro de DAGs. Isso permite:

- **Agendamento**: Executar transformaÃ§Ãµes DBT em horÃ¡rios especÃ­ficos
- **DependÃªncias**: Coordenar execuÃ§Ã£o de DBT apÃ³s ingestÃ£o de dados
- **Monitoramento**: Rastrear execuÃ§Ãµes e falhas de models DBT
- **Retry Logic**: Reexecutar automaticamente em caso de falhas

No prÃ³ximo tÃ³pico, vocÃª aprenderÃ¡ como integrar DBT com Airflow para criar pipelines completos e orquestrados.

### PrÃ³ximos Passos ğŸ¯

Agora que vocÃª compreendeu os fundamentos do DBT, estÃ¡ pronto para aprender como orquestrar pipelines DBT utilizando o **Apache Airflow**, criando soluÃ§Ãµes completas de transformaÃ§Ã£o e orquestraÃ§Ã£o de dados.

### Vamos colocar a mÃ£o na massa? ğŸ’ª
