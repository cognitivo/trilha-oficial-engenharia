# Fase 4 - Orquestração de Pipelines 🎬

## Orquestrando Pipelines com Apache Airflow 🔄

### Objetivo 🎯

Neste projeto, você levará seus conhecimentos de **orquestração** para o próximo nível, utilizando o **Apache Airflow** como a camada de orquestração dos seus pipelines de dados. 🚀

### Descrição do projeto 🛠️

Como **Engenheiro(a) de Dados**, você já finalizou o **Projeto 3** anteriormente. Agora, é hora de trazer **maior controle** para o seu projeto e inserir uma camada de **orquestração** responsável por gerenciar os processos. 🎯

Neste projeto, o desafio é **configurar uma instância EC2** dedicada ao **Airflow** no ambiente AWS, utilizando o **Terraform** para provisionar a infraestrutura. Assim como fez anteriormente com o **Airbyte** e o **Postgres**, você criará um **script de inicialização** que automatiza a instalação e configuração do Airflow ao subir a instância. 🔧

O objetivo é:

1. **Analisar o pipeline** criado no projeto anterior e identificar processos que podem ser orquestrados pelo Airflow.
2. Criar uma ou mais **DAGs** (Directed Acyclic Graphs) para implementar a orquestração do pipeline em **Batch**.
3. Experimentar diferentes abordagens de orquestração, observando como o Airflow pode **otimizar** a execução dos fluxos. ⚙️

### Dicas para o sucesso 💡

- **Revise o pipeline** que você construiu anteriormente. Compreenda os fluxos de dados e **onde o Airflow** pode agregar valor ao automatizar e otimizar os processos.
- **Pense de forma modular**: Como você pode dividir seu pipeline em **tarefas menores** e organizá-las em **DAGs** ou **tasks**? Cada parte pode ser uma tarefa a ser gerenciada pelo Airflow.

Este projeto é uma **oportunidade prática** de explorar o Airflow em um contexto real, aplicando os conceitos que você aprendeu para criar uma solução **funcional** e **otimizada**.

### Boa sorte e mãos à obra! 💪
